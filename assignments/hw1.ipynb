{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Homework 1:** \n",
    "STATS348, UChicago, Spring 2024\n",
    "\n",
    "----------------\n",
    "**Your name here:**\n",
    "\n",
    "----------------\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/aschein/stat_348_2024/blob/main/assignments/hw1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "---\n",
    "\n",
    "## Instructions\n",
    "\n",
    "The purpose of this homework is to apply the concepts raised in week 1 on supervised learning and decision problems:\n",
    "\n",
    "* overfitting / underfitting\n",
    "* CV and model selection\n",
    "* logistic regression\n",
    "* KNNs\n",
    "\n",
    "This homework will also get you familiar with Python and the [scikit-learn](https://scikit-learn.org/stable/) package.\n",
    "\n",
    "For reference, this homework is a close adaption of [homework 1 from the 2021 version of STAT348](https://dynalist.io/d/ehiGZbaDzYG4q9tJvuCrag3U#z=Hu-cB8VnWnu5IXOgZ-3MaF6C&q=%23homework%20).\n",
    "\n",
    "Assignment is due **Saturday March 30, 11:59pm** on GradeScope.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Problem 1:** Elephants\n",
    "\n",
    "Read through [Matthew Stephens' vignette on classifying savannah versus forest elephants](https://stephens999.github.io/fiveMinuteStats/likelihood_ratio_simple_models.html) and then do exercises 2a and 2b from the vignette, which are copied here (and relabeled 1a and 1b).\n",
    "\n",
    "> 1a) Perform the following simulation study. Simulate 1000 tusks (values of $x$) from each of the models $M_S$ and $M_F$. For each simulated tusk compute the LR for $M_S$ vs $M_F$, so you have computed 2000 LRs. Now consider using the LR to classify each tusk as being from a savanna or a forest elephant. Recall that large values for LR indicate support for $M_S$, so a natural classification rule is “classify as savanna if $\\textrm{LR} > c$, otherwise classify as forest” for some threshold $c$. Plot the misclassification rate (= number of tusks wrongly classified/2000) for this rule, as $c$ ranges from 0.01 to 100. What value of $c$ minimizes the misclassification rate? [Hint: the plot will look best if you do things on the log scale, so you could let $\\log_{10}(c)$ vary from -2 to 2 using an equally spaced grid, and plot the misclassification rate on the $y$-axis against $\\log_{10}(c)$ on the $x$-axis.]\n",
    "\n",
    "\n",
    "> 1b) Repeat the above simulation study using 100 tusks from MS and 1900 tusks from MF. What value of $c$ minimizes the misclassification rate? Comment.\n",
    "\n",
    "To complete this problem in Python, here are some useful tools:\n",
    "- To plot you can use [matplotlib](https://matplotlib.org/) and [seaborn](https://seaborn.pydata.org/). You can see the week 1 notebook for examples.\n",
    "\n",
    "- To sample random variables you can use [numpy.random](https://numpy.org/doc/stable/reference/random/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rn\n",
    "\n",
    "# sample a Bernoulli with probability p\n",
    "p = 0.5\n",
    "x = rn.binomial(1, p)\n",
    "\n",
    "# sample n Bernoullis iid with probability p\n",
    "n = 100\n",
    "x = rn.binomial(1, p, size=n)\n",
    "\n",
    "# sample n Bernoullis independently with different probabilities\n",
    "p = np.array([0.1, 0.4, 0.5, 0.1, 0.9])\n",
    "x = rn.binomial(1, p)\n",
    "\n",
    "# this last example uses broadcasting.\n",
    "# See here: https://numpy.org/doc/stable/user/basics.broadcasting.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete the first part of this problem, you should complete the following functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_tusks_forest(size=1000):\n",
    "    \"\"\"Samples from the likelihood of P(x | forest).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    size : int\n",
    "        The number of samples to draw.\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "\n",
    "def simulate_tusks_savannah(size=1000):\n",
    "    \"\"\"Samples from the likelihood of P(x | savannah).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    size : int\n",
    "        The number of samples to draw.\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "\n",
    "def likelihood_forest(x):\n",
    "    \"\"\"Computes the likelihood of the data under the M_F model (i.e., given that the elephant is forest elephant).\"\"\"\n",
    "    # Your code here\n",
    "\n",
    "def likelihood_savannah(x):\n",
    "    \"\"\"Computes the likelihood of the data under the M_S model (i.e., given that the elephant is a savannah elephant).\"\"\"\n",
    "    # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **1a)**: Use the functions above to perform the simulations and generate the plots in 1a.\n",
    "\n",
    "    Use code block below for this. The output should display the plot(s), and show which $c$ minimizes the misclassification rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here for 1a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **1b)** Now do the same for 1b.\n",
    "\n",
    "    Use code block below for this. The output should display the plot(s), and show which $c$ minimizes the misclassification rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here for 1b."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Problem 2:** Digits\n",
    "\n",
    "Consider the [zipcode data from _Elements of Statistical Learning_ (ESL)](https://hastie.su.domains/ElemStatLearn/data.html). Note there is both a train and test set.\n",
    "\n",
    "- **2a)** Download the data and try plotting a few examples of the training data as 16 x 16 images to see if you can see the digits visually as expected. [Hint: Use matplotlib's [imshow](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html) function.] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here for 2a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **2b)** Consider the problem of trying to distinguish the digit 2 from the digit 3. Use the training data to learn classifiers, using:\n",
    "    - logistic regression (un-regularized)\n",
    "    - K nearest neighbors (K-NNs), with $K=1,3,5,7,15$.\n",
    "    \n",
    "    This gives 6 classifiers in total.\n",
    "\n",
    "    To complete this in Python you will want to use [scikit-learn](https://scikit-learn.org/stable/), and refer to the week 1 notebook for examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here for 2b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **2c)** Apply these classifiers to the test data, and plot the misclassification rates for both training data and test data. (Plot the results for K-NN with $K$ on x-axis, and misclassification rate on y-axis, with two different colors for test and training sets. Then put appropriately colored horizontal lines on the same plot---one for test and one for train---indicating the results for logistic regression.)\n",
    "\n",
    "    Your code in the cell below should output this plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here for 2c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **2d)** Repeat the K-NN training as above, but using cross validation (CV) *on the training set* to tune $K$. That is, act like you do not have access to the test data and have to decide what $K$ to use.  How does it do?\n",
    "\n",
    "    Again, for this problem you will want to use [scikit-learn's methods for cross validation](https://scikit-learn.org/stable/modules/cross_validation.html). \n",
    "\n",
    "    Please add code in the cell below, and comment on the results in the space below.\n",
    "\n",
    "----\n",
    "\n",
    "Your text answer here: \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here for 2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **2e)** Suppose now that for some reason it is considered worse to misclassify a 2 as a 3 than vice versa. Specifically, suppose you lose 5 points every time you misclassify a 2 as a 3, but 1 point every time you misclassify a 3 as a 2. Modify your logistic regression classifier to take account of this new loss function. Compute the new loss on the test set for both the modified classifier and the original logistic classifier. \n",
    "\n",
    "Please add code in the cell below, and provide a brief description / justification of your code in the space below.\n",
    "\n",
    "----\n",
    "\n",
    "Your text answer here: \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **2f)** As far as you can, repeat this for the K-NN classifiers (i.e. modify them for the new loss function and compare the loss for modified vs original classifiers). Discuss any challenges you face here. \n",
    "\n",
    "Please add code in the cell below, and provide a discussion of any challenges in the space below.\n",
    "\n",
    "----\n",
    "\n",
    "Your text answer here: \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here for 2f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Problem 3:** Multiclass digits\n",
    "\n",
    "Continuing with the zipcode data, now consider distinguishing the digits 1, 2, and 3. \n",
    "\n",
    "- For this problem, you will be generalizing the things we discussed in class about binary classification to **multiclass classification**, using multinomial logistic regression.\n",
    "\n",
    "- Read Section 4.3.5 of [_An Introduction to Statistical Learning with Applications in Python_](https://www.statlearning.com/) on multinomial logistic regression for background.\n",
    "\n",
    "- You can create a multinomial logistic regression model using scikit-learn as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# an (unregularized) multinomial logistic regression model\n",
    "logreg = LogisticRegression(penalty='none', solver='liblinear', multi_class='multinomial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **3a)** Fit a multinomial logistic regression model to the training data of 1s, 2s, and 3s. Then apply it to the test set, and then calculate and plot the **confusion matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here for 3a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **3b)** Suppose now that for some reason it is considered twice as bad to misclassify a 1 as a 2 than to make any other misclassification. Modify your multinomiallogistic regression classifier to take account of this new loss function. Compute the new loss on the test set for both the modified classifier and the original logistic classifier. \n",
    "\n",
    "Please add code in the cell below, and provide justification of your code in the space below, including any derivations you had to do.\n",
    "\n",
    "----\n",
    "\n",
    "Your text answer here: \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here for 3b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **3c)** Now consider adding $\\ell_2$ regularization to your multinomial logistic regression classifier and answer the question: does it improve performance? Devise some experiments to answer this question convincingly. Use the code block below to implement and run those experiments, and to generate plot(s) that convey the results. Use the space below to briefly describe and justify your experiments, to summarize the results, and to speculate on why regularization does or does not help in this setting.\n",
    "\n",
    "----\n",
    "\n",
    "Your text answer here: \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here for 3c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
